{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from src.cancer_detection.components.model import vgg16_modified, cancerClassifier\n",
    "from src.cancer_detection.components.data_module import ImageTransform\n",
    "from src.cancer_detection.config.configuration import ConfigurationManager\n",
    "from src.cancer_detection.entity.config_dataclasses import TrainingConfig, InfernceConfig \n",
    "from src.cancer_detection.constants import DEVICE\n",
    "from src.cancer_detection import logger\n",
    "from PIL import Image\n",
    "from typing import Type, List, Dict\n",
    "from pathlib import Path\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "\n",
    "class PredictionPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _predict(\n",
    "        training_config: TrainingConfig,\n",
    "        inference_config: InfernceConfig,\n",
    "        image_transformation_pipeline: Type[ImageTransform],\n",
    "        filename : Path\n",
    "    ) -> Dict[str, str]:\n",
    "        \n",
    "        # load model\n",
    "        model = vgg16_modified(training_config)\n",
    "\n",
    "\n",
    "        if inference_config.load_from_local:\n",
    "            # load checkpoint locally\n",
    "            try:\n",
    "                model_ = cancerClassifier.load_from_checkpoint(inference_config.path_to_best_checkpoint_local, model=model, config=training_config)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                logger.info(f\"Error: File '{inference_config.path_to_best_checkpoint_local}' not found.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.info(f\"Error: An unexpected error occurred - {e}\")\n",
    "\n",
    "        else:\n",
    "            checkpoint_url = str(inference_config.URL_to_load_from_drive)\n",
    "            out_file = str(inference_config.best_model_checkpoints_saved_from_URL)\n",
    "\n",
    "            if not inference_config.best_model_checkpoints_saved_from_URL.is_file():\n",
    "                # download the checkpoint from gdrive\n",
    "                logger.info(f\"Downloading data from {checkpoint_url} into file {out_file}\")\n",
    "                file_id = checkpoint_url.split(\"/\")[-2]\n",
    "                prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "                gdown.download(prefix+file_id, out_file)\n",
    "                \n",
    "            model_ = cancerClassifier.load_from_checkpoint(out_file, model=model, config=training_config)\n",
    "\n",
    "        model_.eval()        \n",
    "        # load image\n",
    "        img = Image.open(filename)\n",
    "        # Transformimg Image\n",
    "        test_image = image_transformation_pipeline(img, \"test\").unsqueeze(dim=0).to(DEVICE)\n",
    "\n",
    "        # make predictions\n",
    "        logits = model_(test_image)\n",
    "        preds = torch.argmax(logits, dim = 1)\n",
    "        if preds[0] == 1:\n",
    "            prediction = 'Normal'\n",
    "            return [{ \"image\" : prediction}]\n",
    "        else:\n",
    "            prediction = 'Adenocarcinoma Cancer'\n",
    "            return [{ \"image\" : prediction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image =   # Add path to image here to make it work\n",
    "training_config = ConfigurationManager().get_training_config()\n",
    "inference_config = ConfigurationManager().get_inference_config()\n",
    "image_transformation_pipeline = ImageTransform(training_config.params_image_size[0])\n",
    "\n",
    "preds = PredictionPipeline()\n",
    "preds._predict(training_config, inference_config, image_transformation_pipeline, path_to_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.new(\"RGB\", (224, 224), color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.save(\"image3.png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production_pankaj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
