{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import mlflow\n",
    "from typing import Dict, List, Optional\n",
    "from src.cancer_detection import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    training_data: Path\n",
    "    model_checkpoints: Path \n",
    "    best_model_checkpoints: Path\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    params_epochs: int\n",
    "    params_num_classes: int\n",
    "    params_learning_rate: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cancer_detection.constants import *\n",
    "from src.cancer_detection.utils.common import read_yaml, create_directories\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        \n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training_config = self.config.training\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chest-CT-Scan-data\")\n",
    "        \n",
    "        create_directories([Path(training_config.root_dir)])\n",
    "        create_directories([Path(training_config.model_checkpoints)])\n",
    "        create_directories([Path(training_config.best_model_checkpoints)])\n",
    "\n",
    "        training_config_ = TrainingConfig(\n",
    "            root_dir=Path(training_config.root_dir),\n",
    "            training_data=Path(training_data),\n",
    "            model_checkpoints=training_config.model_checkpoints,\n",
    "            best_model_checkpoints=training_config.best_model_checkpoints,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_num_classes=params.CLASSES,\n",
    "            params_learning_rate=params.LEARNING_RATE\n",
    "        )\n",
    "\n",
    "        return training_config_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "class ImageTransform():\n",
    "    def __init__(\n",
    "            self,\n",
    "            img_size: int  = 224, \n",
    "            mean: Optional[list] = None,\n",
    "            std: Optional[list] = None\n",
    "        ):\n",
    "\n",
    "        if mean is None:\n",
    "            self.mean = [0.485, 0.456, 0.406]\n",
    "        if std is None:\n",
    "            self.std = [0.229, 0.224, 0.225]\n",
    "        \n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(img_size, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(img_size),\n",
    "                transforms.ToTensor()\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(img_size),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def __call__(self, img : Image.Image, phase : str) -> torch.tensor:\n",
    "        img = self.data_transform[phase](img)\n",
    "\n",
    "        if img.shape[0] == 1:\n",
    "            logger.info(f'logging shape : \\n {img.shape}, dtype : {img.dtype}')\n",
    "            img = torch.repeat_interleave(img, 3, dim=0)\n",
    "        img = img[:3, :, :]\n",
    "        \n",
    "        # Normalize\n",
    "        img = transforms.functional.normalize(img, mean=self.mean, std=self.std)\n",
    "        return img\n",
    "    \n",
    "\n",
    "class cancerDataset(Dataset):\n",
    "    \"\"\"A PyTorch Dataset for the cancer image data.\"\"\"\n",
    "    def __init__(self, file_list, transform_fun=None, phase='train') -> None:\n",
    "        # self.path = path\n",
    "        # self.files = glob.glob(os.path.join(self.path, '**/*.png'), recursive=True)\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform_fun\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of examples in the dataset.\"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        # Transformimg Image\n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "        \n",
    "        # Get Label\n",
    "        label = img_path.split(\"/\")[-2]\n",
    "        if label == 'adenocarcinoma':\n",
    "            label = 0\n",
    "        elif label == 'normal':\n",
    "            label = 1\n",
    "\n",
    "        return img_transformed, label\n",
    "    \n",
    "\n",
    "\n",
    "class cancerDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, path, img_size, batch_size, num_workers, seed: Optional[int] = None) -> None:\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "        self.img_size = img_size\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "\n",
    "    def setup(self,  stage: str) -> None:\n",
    "        \"\"\"Splits the dataset into training, validation, and test sets.\"\"\"\n",
    "\n",
    "        self.files = np.array(glob.glob(os.path.join(self.path, '**/*.png'), recursive=True))\n",
    "        train_size = int(0.8 * len(self.files))\n",
    "        val_size = int(0.1 * len(self.files))\n",
    "        indices = np.arange(len(self.files))\n",
    "        self.rng.shuffle(indices)\n",
    "        train_indices = indices[:train_size]\n",
    "        val_indices = indices[train_size : train_size + val_size]\n",
    "        test_indices = indices[train_size + val_size :]\n",
    "        self.train_files = self.files[train_indices]\n",
    "        self.val_files   = self.files[val_indices]\n",
    "        self.test_files  = self.files[test_indices]\n",
    "            \n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Returns a DataLoader for the training set.\"\"\"\n",
    "        dataset = cancerDataset(self.train_files, ImageTransform(self.img_size), 'train')\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Returns a DataLoader for the validation set.\"\"\"\n",
    "        dataset = cancerDataset(self.val_files, ImageTransform(self.img_size), 'val')\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Returns a DataLoader for the test set.\"\"\"\n",
    "        dataset = cancerDataset(self.test_files,  ImageTransform(self.img_size), 'test')\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        dataset = cancerDataset(self.test_files)\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------- transfer learning model----------------------- #\n",
    "class vgg16_modified(nn.Module):\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model =  torchvision.models.vgg16(pretrained=True)\n",
    "        self.model.classifier[6] = nn.Linear(\n",
    "            in_features=self.model.classifier[6].in_features,\n",
    "            out_features=self.config.params_num_classes\n",
    "        )\n",
    "        \n",
    "        # Specify the layers for updating\n",
    "        params_to_update = []\n",
    "        update_params_name = ['classifier.6.weight', 'classifier.6.bias']\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in update_params_name:\n",
    "                param.requires_grad = True\n",
    "                params_to_update.append(param)\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "\n",
    "\n",
    "# ---------------------------- Lightning Module ----------------------------- #\n",
    "class cancerClassifier(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, config: TrainingConfig) -> None:\n",
    "        \"\"\"Load the CNN classifier.\"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        # define loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, batch: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Forward pass of the model to return output predictions.\"\"\"\n",
    "        return self.model(batch)\n",
    "\n",
    "\n",
    "    def training_step(self, batch: torch.tensor, batch_idx: int) -> torch.tensor:\n",
    "        \"\"\"Perform a single traing step, returning the loss on a training batch.\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        preds = self.predict_step(logits)\n",
    "        acc = torch.sum(preds == y).float()/len(y)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch: torch.tensor, batch_idx: int) -> None:\n",
    "        \"\"\"Perform a single validation step.\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True)\n",
    "\n",
    "        preds = self.predict_step(logits)\n",
    "        acc = torch.sum(preds == y).float()/len(y)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "    def test_step(self, batch: torch.tensor, batch_idx: int) -> None:\n",
    "        \"\"\"Perform a single test step.\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "\n",
    "        preds = self.predict_step(logits)\n",
    "        acc = torch.sum(preds == y).float()/len(y)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        \"\"\"Configure the optimizer to use for training.\"\"\"\n",
    "        return torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.config.params_learning_rate, # add learning rate here\n",
    "        )\n",
    "\n",
    "\n",
    "    def predict_step(self, logits: torch.tensor) -> torch.tensor: \n",
    "        preds = torch.argmax(logits, dim = 1)\n",
    "        return preds\n",
    "\n",
    "\n",
    "\n",
    "def train(config : TrainingConfig, fast_dev_run: bool = False):\n",
    "    \"\"\"Run the full data-loading and model-training loop.\"\"\"\n",
    "    \n",
    "    # Set seed to control randomness\n",
    "    seed = 123\n",
    "    torch.manual_seed(seed)    \n",
    "\n",
    "    # Prepare data module\n",
    "    num_workers = max(0, (os.cpu_count() or 1) - 1)\n",
    "    datamodule = cancerDataModule(\n",
    "        path=config.training_data,\n",
    "        batch_size=config.params_batch_size,\n",
    "        num_workers=num_workers,\n",
    "        img_size=config.params_image_size[0]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            dirpath=config.model_checkpoints,\n",
    "            filename=\"validation-{epoch}-{step}-{val_loss:.1f}\",\n",
    "            monitor=\"val_acc\",\n",
    "            save_top_k=1,  # save all checkpoints\n",
    "            mode=\"max\",\n",
    "            every_n_epochs=5,\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_acc\",\n",
    "            mode=\"max\",\n",
    "            patience=20,\n",
    "            verbose=True,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # model\n",
    "    model = vgg16_modified(config)\n",
    "    # Train model\n",
    "    learner = cancerClassifier(model, config)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.params_epochs,\n",
    "        fast_dev_run=fast_dev_run,\n",
    "        enable_checkpointing=True,\n",
    "        callbacks = callbacks\n",
    "    )\n",
    "\n",
    "\n",
    "    client = MlflowClient()\n",
    "    experiment_name = \"vgg16classifier\"\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    run_name = f\"{timestamp}\"\n",
    "\n",
    "    try:\n",
    "        experiment_id = client.create_experiment(experiment_name)\n",
    "        experiment = client.get_experiment(experiment_id)\n",
    "    except MlflowException:\n",
    "        experiment = client.get_experiment_by_name(experiment_name)\n",
    "        experiment_id = experiment.experiment_id\n",
    "\n",
    "    \n",
    "    # Fetch experiment metadata information\n",
    "    logger.info(f\"Name: {experiment.name}\")\n",
    "    logger.info(f\"Experiment_id: {experiment.experiment_id}\")\n",
    "    logger.info(f\"Artifact Location: {experiment.artifact_location}\")\n",
    "    logger.info(f\"Tags: {experiment.tags}\")\n",
    "    logger.info(f\"Lifecycle_stage: {experiment.lifecycle_stage}\")\n",
    "\n",
    "    mlflow.set_tracking_uri(\"ADD URI HERE\")\n",
    "    \n",
    "    # Activate auto logging for pytorch lightning module\n",
    "    mlflow.pytorch.autolog(log_models=False)\n",
    "\n",
    "     # Start MLflow run\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n",
    "        mlflow.log_params(config.__dict__)\n",
    "        logger.info(\"Training model...\")\n",
    "        trainer.fit(learner, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = train(training_config)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production_pankaj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
